# Java 基础知识

### 1. 继承，多态，封装，抽象



### 2. 重写和重载的区别

####  	2.1重写

​			从字面上看，重写就是 重新写一遍的意思。其实就是**在子类中把父类本身有的方法**重新写一遍。子类继承了父类原有的方法，但有时子类并不想原封不动		的继承父类中的某个方法，所以**在方法名，参数列表，返回类型(除过子类中方法的返回值是父类中方法返回值的子类时)都相同的情况下，** 对方法体进行修改		或重写，这就是重写。但要注意**子类函数的访问修饰权限不能少于父类的。**

#### 	  2.2重载

​			在一个类中，同名的方法如果有不同的参数列表（**参数类型不同、参数个数不同甚至是参数顺序不同**）则视为重载。同时，重载对返回类型没有要求，可以		相同也可以不同，但**不能通过返回类型是否相同来判断重载**。



### 3. 类加载顺序

​		父类的静态字段——>父类静态代码块——>子类静态字段——>子类静态代码块——>

​		父类成员变量（非静态字段）——>父类非静态代码块——>父类构造器——>子类成员变量——>子类非静态代码块——>子类构造器



### 4. final 关键字的作用

#### 	4.1用来修饰一个引用

   	1.如果引用为基本数据类型，则该引用为常量，该值无法修改；

​	   2.如果引用为引用数据类型，比如对象、数组，则该对象、数组本身可以修改，但指向该对象或数组的地址的引用不能修改。

​	   3.如果引用时类的成员变量，则必须当场赋值，否则编译会报错。	

```java
final class Person {
    String name ="zs";    //3. 此处不赋值会报错
    //final int age;
    final int age = 10;
}
public class Demo01 {
    public static void main(String[] args) {        //1. 基本数组类型为常量，无法修改
        final int i = 9;
        //i = 10;               //2. 地址不能修改，但是对象本身的属性可以修改
        Person p = new Person();
        p.name = "lisi";
        final int[] arr = {1,2,3,45};
        arr[3] = 999;
        //arr = new int[]{1,4,56,78};
    }
}
```

#### 	 

#### 	   4.2用来修饰一个方法

  			当使用final修饰方法时，这个方法将成为最终方法，无法被子类重写。但是，该方法仍然可以被继承。

#### 	 

####  	  4.3用来修饰类

​             当用final修改类时，该类成为最终类，无法被继承。简称为“断子绝孙类”。



### 5. static 关键字的作用

> 参考文献：https://www.cnblogs.com/swisszhang/p/9892992.html
>

static关键字最基本的用法是：

#### 	5.1 被static修饰的变量属于类变量，可以通过**类名.变量名**直接引用，而不需要new出一个类来

#### 	5.2 被static修饰的方法属于类方法，可以通过**类名.方法名**直接引用，而不需要new出一个类来

​	 5.3 被static修饰的变量、被static修饰的方法统一属于类的**静态资源，是类实例之间共享的，换言之，一处变、处处变**。JDK把不同的静态资源放在了不同的类		   中而不把所有静态资源放在一个类里面，很多人可能想当然认为当然要这么做，但是是否想过为什么要这么做呢？个人认为主要有三个好处：

​			1、不同的类有自己的静态资源，这可以实现静态资源分类。比如和数学相关的静态资源放在java.lang.Math中，和日历相关的静态资源放在  java.util.Calendar中，这样就很清晰了

​			2、避免重名。不同的类之间有重名的静态变量名、静态方法名也是很正常的，如果所有的都放在一起不可避免的一个问题就是名字重复，这时候怎么办？		分类放置就好了。

​			3、避免静态资源类无限膨胀，这很好理解。



### 6.==和 equals 的区别

####  6.1 ==

​     对于基本类型来说是值比较，对于引用类型来说是比较的是引用

####  6.2 equals 

​	默认情况下是引用比较，只是很多类重新了 equals 方法，比如 String、Integer 等把它 变成了值比较，

所以一般情况下 equals 比较的是值是否相等。



### 7. hashCode()与 equals()

​	  1.equals()相等的两个对象他们的hashCode()肯定相等，也就是用equal()对比是绝对可靠的。

​      2.hashCode()相等的两个对象他们的equals()不一定相等，也就是hashCode()不是绝对可靠的。



### 8. Java 泛型了解么？什么是类型擦除？介绍一下常用的通配符？

> 参考文献：[https://www.cnblogs.com/demingblog/p/5495610.html](https://www.cnblogs.com/demingblog/p/5495610.html)
>

#### 8.1 什么是 Java 泛型

​	泛型是Java SE 1.5的新特性，泛型的本质是参数化类型，也就是说所操作的数据类型被指定为一个参数。
​	这种参数类型可以用在类、接口和方法的创建中，分别称为泛型类、泛型接口、泛型方法。

>   通俗的讲，泛型就是操作类型的 占位符，即：假设占位符为T，那么此次声明的数据结构操作的数据类型为T类型。



#### 8.2 什么是类型擦除

　先看一个例子，Operate类如下：

```java
public class Operate {

    public static void main(String[] args) {
        List<String> names=new ArrayList<String>();
        names.add("Jack");
        names.add("Tom");
        names.add("peter");
        for(String name:names){
            System.out.println("wellcome:"+name);
        }
    }

}
```

其对应的class文件**反编译**之后，我们使用*java-gui反编译.exe*  查看编译之后的代码如下

```java
public class Operate {
    public static void main(String[] args) {
        List names=new ArrayList();
        names.add("Jack");
        names.add("Tom");
        names.add("peter");
        for(String name:names){
            System.out.println("wellcome:"+name);
        }
    }
}
```

> 发现没有，根本没有<String> 这一部分了。这个限制为String类型的泛型被“擦除”了。写代码的时候，泛型会做校验，类型不对应的，无法add,但是编译之后边去掉了泛型类型



#### 8.3 泛型通配符

我们在定义泛型类，泛型方法，泛型接口的时候经常会碰见很多不同的通配符，比如 T，E，K，V 等等，这些通配符又都是什么意思呢？

**常用的 T，E，K，V，？**

本质上这些个都是通配符，没啥区别，只不过是编码时的一种约定俗成的东西。比如上述代码中的 T ，我们可以换成 A-Z 之间的任何一个 字母都可以，并不会影响程序的正常运行，但是如果换成其他的字母代替 T ，在可读性上可能会弱一些。**通常情况下，T，E，K，V，？ 是这样约定的：**

- ？ 表示不确定的 java 类型
- T (type) 表示具体的一个java类型
- K V (key value) 分别代表java键值中的Key Value
- E (element) 代表Element



### 9.  Java 中的几种基本数据类型是什么？对应的包装类型是什么？各自占用多少字节呢？

![9-1](picture\9-1.png)

![9-2](picture\9-2.jpg)





###  10. Collection 集合如何排序

​		有一个列表：List list
​		现在使用 **Collections** 对其进行排序：

```java
public static void main(String[] args) {
    List<Integer> list = new ArrayList<>();
    list.add(3);
    list.add(10);
    list.add(2);
    list.add(5);
    Collections.sort(list, new Comparator<Integer>() {
        @Override
        public int compare(Integer o1, Integer o2) {
            return o1.compareTo(o2);//升序
        }
    });
    System.out.println(list);
}
```

​		如果列表里是个Map：List<Map<String,Object>> list
​		也可以使用 **Collections** 对其进行排序：

```java
public static void main(String[] args) {
    List<Map<String,Object>> list=new ArrayList<>();
    Map<String,Object> map1=new HashMap<>();
    map1.put("name","name1");
    map1.put("age",2);
    Map<String,Object> map2=new HashMap<>();
    map2.put("name","name2");
    map2.put("age",3);
    list.add(map1);
    list.add(map2);
    //按照map中total字段排序
    Collections.sort(list,new Comparator<Map<String,Object>>(){
        public int compare(Map<String,Object> o1 ,Map<String,Object> o2){
            Integer num1=(Integer)o1.get("age");
            Integer num2=(Integer)o2.get("age");
            return num2.compareTo(num1);   //降序
            //return num1.compareTo(num2); //升序
        }
    });
    System.out.println(list);
}
```



### 11.  AutoColse 接口做什么用的

> ​    在JDK1.7的时候就提出了一种自动关闭资源的想法，所以AutoCloseable接口就诞生了，查看AutoCloseable源码会发现，接口只有一个方法close()



```java
package java.lang;

public interface AutoCloseable {
    void close() throws Exception;
}
```





### 12. ThreadLocal 实现原理 数据结构 生命周期

> **参考文献：**https://baijiahao.baidu.com/s?id=1653790035315010634&wfr=spider&for=pc

### 13. volatile 修饰符的作用

> 参考文献：https://zhuanlan.zhihu.com/p/138819184
>

### 14. Error 和 Exception 区别

### 15.[正则表达式](file:///D:/Taimei/IdeaSpaceWorkTest/knowledge/t5/正则_T5.md)

### 16. java 字符集如何指定，默认是什么字符集



## 17.java 中 NIO，BIO 区别

> 参考文献：https://blog.csdn.net/m0_38109046/article/details/89449305
>

## 18.jvm 内存分配模型，GC 方式，GC 算法



# Mybaits

### 1. #和\$的区别

[https://blog.csdn.net/siwuxie095/article/details/79190856](https://blog.csdn.net/siwuxie095/article/details/79190856)

最大的区别是#能防止SQL注入，而$不能防止SQL注入

> （1）不论是单个参数，还是多个参数，一律都建议使用注解@Param("")
>
> （2）能用 #{} 的地方就用 #{}，不用或少用 ${}
>
> （3）表名作参数时，必须用 ${}。如：select * from ${tableName}
>
> （4）order by 时，必须用 ${}。如：select * from t_user order by ${columnName}
>
> （5）使用 ${} 时，要注意何时加或不加单引号，即 ${} 和 '${}'

为什么可以防止SQL注入

> {}在mybatis中的底层是运用了PreparedStatement 预编译，传入的参数会以 ? 形式显示，因为sql的输入只有在sql编译的时候起作用，当sql预编译完后，传入的参数就仅仅是参数，不会参与sql语句的生成，而${}则没有使用预编译，传入的参数直接和sql进行拼接，由此会产生sql注入的漏洞。



### 2. foreach 如何用

foreach元素的属性主要有item，index，collection，open，separator，close

> - **item：**集合中元素迭代时的别名，该参数为必选。
> - **index**：在list和数组中,index是元素的序号，在map中，index是元素的key，该参数可选
> - **open**：foreach代码的开始符号，一般是(和close=")"合用。常用在in(),values()时。该参数可选
> - **separator**：元素之间的分隔符，例如在in()的时候，separator=","会自动在元素中间用“,“隔开，避免手动输入逗号导致sql错误，如in(1,2,)这样。该参数可选。
> - **close:** foreach代码的关闭符号，一般是)和open="("合用。常用在in(),values()时。该参数可选。
> - **collection:** 要做foreach的对象，作为入参时，List对象默认用"list"代替作为键，数组对象有"array"代替作为键，Map对象没有默认的键。当然在作为入参时可以使用@Param("keyName")来设置键，设置keyName后，list,array将会失效。 除了入参这种情况外，还有一种作为参数对象的某个字段的时候。举个例子：如果User有属性List ids。入参是User对象，那么这个collection = "ids".***如果User有属性Ids ids;其中Ids是个对象，Ids有个属性List id;入参是User对象，那么collection = "ids.id"

#### 2.1. Array的mapper写法：

##### 注：array的写法中collection中的值必须是array,不能写Array，会报错的。但传参的命名可以不是array

```java
List<User>selectUserArr(int []arr);
```

```java
List<User>userArray=userMapper.selectUserArr(arr);
```

```xml
<select id="selectUserArr" resultMap="BaseResultMap">
    SELECT
    <include refid="Base_Column_List" />
    from user
    where id in
    <foreach collection="array" item="id" open="(" separator="," close=")">
        #{id}
    </foreach>
</select>
```



#### 2.2. List

##### 注：list写法中collection中的值必须是list,也不能是List,但传来的参数命名可以不一定是list

```java
List<User>selectUserList(List list1);
```

```java
List<User>userList=userMapper.selectUserList(list1);
```

```xml
<select id="selectUserList" resultMap="BaseResultMap">
    SELECT
    <include refid="Base_Column_List" />
    from user
    where id in
    <foreach collection="list" item="id" open="(" separator="," close=")">
        #{id}
    </foreach>
</select>
```



#### 2.3. map

##### 注：map写法中的collection中填的是map的key值，不对应就会报错

```
List<User>selectUserMap(Map map);
```

```
map.put("map1",map1);
List<User> userMap=userMapper.selectUserMap(map);
```

```xml
<select id="selectUserMap" resultMap="BaseResultMap">
    SELECT
    <include refid="Base_Column_List" />
    from user
    where id in
    <foreach collection="map1" item="id" open="(" separator="," close=")">
        #{id}
    </foreach>
</select>
<!-- 插入数据:返回记录主键id值 --> 
<insert id="insert" useGeneratedKeys="true" keyProperty="id"  keyColumn="id"> 	
insert  into stu (name,age) values (#{name},#{age}) 
</insert>
```



### 3. 如何批量 insert，如何返回 insert 后的自增 Id

> 在xml中定义useGeneratedKeys为true,返回主键id的值,keyProperty和keyColumn分别代表数据库记录主键字段和java对象成员属性名

```xml
<!-- 插入数据:返回记录主键id值 --> 
<insert id="insert" useGeneratedKeys="true" keyProperty="id"  keyColumn="id"> 	
insert  into stu (name,age) values (#{name},#{age}) 
</insert>
```



# Spring 家族

### 1. IOC 概念 如何解决循环依赖

[https://blog.csdn.net/lwyyyyyy/article/details/107202146](https://blog.csdn.net/lwyyyyyy/article/details/107202146)

- 原理

> SpringIOC解决循环依赖的思路就是依靠**缓存**，同时还得引出个概念即**早期暴露引用**。我们知道在IOC容器里bean的初始化的过程分为三个步骤：创建实例、属性注入实例、回调实例实现的接口方法。解决思路就在这：当我们创建实例与属性注入实例这俩个步骤之间的时候，我们引入缓存，将这些已经创建好但是并没有注入属性的实例放到缓存里，而这些放在缓存里但是没有被注入属性的实例对象，就是解决循环依赖的方法，打个比方：A对象的创建需要引用到B对象，而B对象的创建也需要A对象，而此时当B对象创建的时候直接从缓存里引用A对象（虽然不是完全体A对象，毕竟没有赋值处理），当B对象完成创建以后再被A对象引用进去，则A对象也完成了创建。
> **这就是SpringIOC解决bean直接循环依赖的思路**当然有一个小问题，*IOC能够解决的只能是属性之间的循环依赖，如果有bean之间的构造器相互依赖则就解决不了只能报错了。*



### 2. 事务传播机制

#### 2.1 死活不要事务

Propagation.NEVER

>  以非事务方式进行，如果存在事务则抛出异常

```java
@Transactional
public void laoda(String firstName,String toName,Integer money){
    accountDao.out(firstName,money);
    try {
        transactionalService.xiaodi(toName,money);
    }catch (Exception e){
        e.printStackTrace();
    }
    int x =10;
    if(x == 10){
        throw  new RuntimeException("出错了");
    }
}
//执行时报错,因为laoda()添加了事务，而xiaodi()是Propagation.NEVER
//org.springframework.transaction.IllegalTransactionStateException: Existing transaction found for transaction marked with propagation 'never'
@Transactional(propagation = Propagation.NEVER) 
public void xiaodi(String toName,Integer money){
    accountDao.in(toName,money);
    int x =10;
    if(x == 10){
        throw  new RuntimeException("出错了");
    }
}
```

Propagation.NOT_SUPPORTED

> 以非事务方式执行，如果当前存在事务则将当前事务挂起

```java
// 因为当前事务被挂起，导致account表锁死，xiaodi()也是操作的accout，所以造成死锁，我们这里假设它没有死锁，laoda()有事务回滚，xiaodi()，没有事务不回滚
@Transactional(propagation = Propagation.REQUIRED)
public void laoda(String firstName,String toName,Integer money){
    accountDao.out(firstName,money);
    try {
        transactionalService.xiaodi(toName,money);
    }catch (Exception e){
        e.printStackTrace();
    }
    int x =10;
    if(x == 10){
        throw  new RuntimeException("出错了");
    }
}

@Transactional(propagation = Propagation.NOT_SUPPORTED)
public void xiaodi(String toName,Integer money){
    accountDao.in(toName,money); //虽然报错，但是是以非事务形式执行，所以数据不会回滚
    int x =10;
    if(x == 10){
        throw  new RuntimeException("出错了");
    }
}
```



#### 2.2 可有可无的

Propagation.SUPPORTS

> 支持当前事务，如果没有事务的话以非事务方式执行

```java
@Transactional
public void laoda(String firstName,String toName,Integer money){
    accountDao.out(firstName,money);
    try {
        transactionalService.xiaodi(toName,money);
    }catch (Exception e){
        e.printStackTrace();
    }
    int x =10;
    if(x == 10){
        throw  new RuntimeException("出错了");
    }
}
// 因为laoda()有事务，所以xiaodi()也会使用同样的事务，如果laoda()没有事务，xiaodi()也没有事务
@Transactional(propagation = Propagation.SUPPORTS)
public void xiaodi(String toName,Integer money){
    accountDao.in(toName,money);
    int x =10;
    if(x == 10){
        throw  new RuntimeException("出错了");
    }
}
```



#### 2.3 必须要有的

Propagation.REQUIRES_NEW

> 有没有都新建事务，如果原来有事务，就将原来的挂起

```java
@Transactional
public void laoda(String firstName,String toName,Integer money){
    accountDao.out(firstName,money);
    try {
        transactionalService.xiaodi(toName,money);
    }catch (Exception e){
        e.printStackTrace();
    }
    int x =10;
    if(x == 10){
        throw  new RuntimeException("出错了");
    }
}
// laoda()的事务和xiaodi()的事务互不影响，因为laoda()的事务被挂起了
@Transactional(propagation = Propagation.REQUIRES_NEW)
public void xiaodi(String toName,Integer money){
    accountDao.in(toName,money);
    int x =10;
    if(x == 10){
        throw  new RuntimeException("出错了");
    }
}
```



Propagation.NESTED

>  如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则进行与PROPAGATION_REQUIRED类似的操作
>
> laoda()出现异常回滚，xiaodi()也会回滚；xiaodi()出现异常回滚，laoda()不会回滚；固父会影响子，子的事务不会影响父



Propagation.REQUIRED

> 如果没有，就新建一个事务，如果有，就加入当前事务



### 3. @Autowrie @Resource 的区别

- `@Resource`和`@Autowired`都可以用来装配bean，都可以用于字段或setter方法。
- `@Autowired`默认**按类型**装配，默认情况下必须要求依赖对象必须存在，如果要允许null值，可以设置它的required属性为false。
- `@Resource`默认**按名称**装配，当找不到与名称匹配的bean时才按照类型进行装配。名称可以通过name属性指定，如果没有指定name属性，当注解写在字段上时，默认取字段名，当注解写在setter方法上时，默认取属性名进行装配。



### 4. @Qualifier 的作用

> 简单的理解就是：
> （1）在使用@Autowire自动注入的时候，加上@Qualifier(“example”)可以指定注入哪个对象；
> （2）可以作为筛选的限定符，我们在做自定义注解时可以在其定义上增加@Qualifier，用来筛选需要的对象。这个理解看下面的代码吧，不好解释。

```java
// @Autowire和@Qualifier配合使用效果和@Resource一样
@Autowired(required = false) @Qualifier("example") 
private Example example;

@Resource(name = "example") 
private Example example;
```



### 5. spring 动态代理有几种方式，有什么区别

> **参考文献：**https://blog.csdn.net/qq_40694145/article/details/107005166

#### 5.1spring 动态代理有几种方式

​	JDK动态代理,基于接口(默认代理模式)，CGLIB动态代理（若要使用需要进行配置）



# 并发

## **1.1 java各种锁的介绍**

> **参考文献：**[**https://www.cnblogs.com/jyroy/p/11365935.html**](https://www.cnblogs.com/jyroy/p/11365935.html)



## **1.2 synchronized与Lock的区别**

> **参考文献：**[**https://www.cnblogs.com/iyyy/p/7993788.html**](https://www.cnblogs.com/iyyy/p/7993788.html)



## 1.3 线程之间是如何通信的

> **参考文献：**https://blog.csdn.net/jsjsjs1789/article/details/104044510

java线程之间的通信方式总共有 8 种，分别是
`volatile、synchronized、interrupt、wait、notify、notifyAll、join、管道输入/输出`，

### 1.3.1 通过 join

把指定的线程加入到当前线程，可以将两个交替执行的线程合并为顺序执行。

比如在线程B中调用了线程A的Join()方法，直到线程A执行完毕后，才会继续执行线程B。

```java
public static void main(String[] args) {
    Thread a = new Thread(() -> {
        try {
            Thread.sleep(1000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        System.out.println(new Date() +":这是t1");
    });

    Thread b = new Thread(() -> {
        try {
            // a线程执行完毕后，再执行线程b
            a.join();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        System.out.println(new Date() +":这是t2");
    });

    a.start();
    b.start();
}
```



### 1.3.2 wait、notify、notifyAll

> **参考文献：**https://www.cnblogs.com/moongeek/p/7631447.html

> 1.notify 只能随机唤醒一个 WaitSet 中的线程，这时如果有其它线程也在等待，那么就可能唤醒不了正确的线程，称之为【虚假唤醒】
>
> 解决方法，改为 notifyAll
>
> 2.**sleep(long n)** **和** **wait(long n)** **的区别**
>
> ​    1) sleep 是 Thread 方法，而 wait 是 Object 的方法 
>
> ​    2) sleep 不需要强制和 synchronized 配合使用，但 wait 需要和 synchronized 一起用 
>
>    3) sleep 在睡眠的同时，不会释放对象锁的，但 wait 在等待的时候会释放对象锁 
>
>    4) 它们状态 TIMED_WAITING



### 1.3.3 interrupt

> - interrupt()，在一个线程中调用另一个线程的interrupt()方法，即会向那个线程发出信号——线程中断状态已被设置。至于那个线程何去何从，由具体的代码实现决定。
> - isInterrupted()，用来判断当前线程的中断状态(true or false)。
> - interrupted()是个Thread的static方法，用来恢复中断状态，名字起得额🙄。

```java
 public static void main(String[] args) throws InterruptedException {
        Thread t2 = new Thread(()->{
            while(true) {
                boolean interrupted = Thread.currentThread().isInterrupted();
                // 根据打断状态来决定是否中单该线程
                if(interrupted) {
                    System.out.println(" 打断状态: "+interrupted);
                /*    //可以恢复中断状态,恢复后仍然可以继续打印 开心
                    Thread.currentThread().interrupted();*/
                    break;
                }
                System.out.println("开心");
            }
        }, "t2");
        t2.start();
        Thread.sleep(2000);
        t2.interrupt();
 }
```



### 1.4 死锁的产生与解决

> **参考文献：**https://www.cnblogs.com/JimmyFanHome/p/9914562.html





# 数据结构

## 1.队列

> **参考文献：**https://www.cnblogs.com/TimVerion/p/11194552.html

> **队列（queue）是只允许在一端进行插入操作，而在另一端进行删除操作的线性表。**
>
> **队列是一种先进先出（First in First Out）的线性表，简称FIFO。允许插入的一端称为队尾，允许删除的一端称为队头**



## 2.栈

> 栈是一种只能从表的一端存取数据且遵循 "先进后出" 原则的线性存储结构。



## 3.链表和数组

> **参考文献：** https://blog.csdn.net/weibo1230123/article/details/82011889



## 4.树

### 4.1 二叉树

> **左节点比根节点小，右节点比根节点大(这样有个坏处就是顺序插入时，可能变成链表的形式)**

![数据结构-1](\picture\数据结构-二叉树1.gif)



![数据结构-2](\picture\数据结构-二叉树2.gif)



### 4.2 平衡树

> 平衡树（Balance Tree，BT）指的是，任意节点的子树的高度差都小于等于 1。
>
> 常见的符合平衡树的有 AVL 树（二叉平衡搜索树），B 树（多路平衡搜索树，2-3 树，2-3-4 树中的一种），红黑树等。



#### 4.2.1 AVL 树

> 是指任意节点的两个子树的高度差不超过 1 的平衡树。又称自平衡二叉搜索树。
>
> **防止了二叉树形成链表的弊端，为了保证平衡（最短支树和最长支数最长不能超过1，会自动的旋转，提高了性能，但是降低了插入性能）**

![数据结构-3](\picture\数据结构-AVL树.gif)



#### 4.2.2 红黑树

> **防止了AVL树的插入性能降低问题(最短支树和最长支数最长不能超过2倍，在查询和插入之间寻找了个平衡)**
>
> 性质1：每个节点要么是黑色，要么是红色。
>
> 性质2：根节点是黑色。
>
> 性质3：每个叶子节点（NIL）是黑色。
>
> 性质4：每个红色结点的两个子结点一定都是黑色。
>
> **性质5：任意一结点到每个叶子结点的路径都包含数量相同的黑结点。**

![红黑树](picture\数据结构-红黑树.png)

#### 4.2.3 B树

> 参考文献：http://www.liuzk.com/410.html
>
> B 树相对于平衡二叉树，InnoDB 中页的默认大小是 16KB,每个节点存储了更多的键值（key）和数据（data），并且每个节点拥有更多的子节点，子节点的个数一般称为阶，上述图中的 B 树为 3 阶 B 树，高度也会很低

基于这个特性，B 树查找数据读取磁盘的次数将会很少，数据的查找效率也会比平衡二叉树高很多。

假如我们要查找 id=28 的用户信息，那么我们在上图 B 树中查找的流程如下：

- 先找到根节点也就是页 1，判断 28 在键值 17 和 35 之间，那么我们根据页 1 中的指针 p2 找到页 3。
- 将 28 和页 3 中的键值相比较，28 在 26 和 30 之间，我们根据页 3 中的指针 p2 找到页 8。
- 将 28 和页 8 中的键值相比较，发现有匹配的键值 28，键值 28 对应的用户信息为（28，bv）。

![B树](picture\数据结构-B树.png)

#### 4.2.4 B+树

> 参考文献：http://www.liuzk.com/410.html
>
> ①B+ 树非叶子节点上是不存储数据的，仅存储键值，而 B 树节点中不仅存储键值，也会存储数据,之所以这么做是因为在数据库中页的大小是固定的，InnoDB 中页的默认大小是 16KB。如果不存储数据，那么就会存储更多的键值，相应的树的阶数（节点的子节点树）就会更大，树就会更矮更胖，如此一来我们查找数据进行磁盘的 IO 次数又会再次减少，数据查询的效率也会更快。
>
> ②因为 B+ 树索引的所有数据均存储在叶子节点，而且数据是按照顺序排列的。

![数据结构-B+树](picture\数据结构-B+树.png)





# 数据库

## 1.事务隔离级别

#### 1.1 **Read Uncommitted（脏读）**

​	在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read）。

#### 1.2 **Read Committed（不可重复读）**

​	这是大多数数据库系统的默认隔离级别（但不是MySQL默认的）。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。这种隔离级别 也支持所谓的不可重复读（Nonrepeatable Read），因为同一事务的其他实例在该实例处理其间可能会有新的commit，所以同一select可能返回不同结果。

#### 1.3  **Repeatable Read（可重复读）**

​	这是MySQL的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过理论上，这会导致另一个棘手的问题：幻读 （Phantom Read）。简单的说，幻读指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行。InnoDB和Falcon存储引擎通过多版本并发控制（MVCC，Multiversion Concurrency Control）机制解决了该问题。

#### 1.4 **Serializable（可串行化）**

​	这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。 



## 2.事务的 ACID 特性

1 、原子性。事务是数据库的逻辑工作单位，事务中包含的各操作要么都做，要么都不做

2 、一致性。事 务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。因此当数据库只包含成功事务提交的结果时，就说数据库处于一致性状态。如果数据库系统 运行中发生故障，有些事务尚未完成就被迫中断，这些未完成事务对数据库所做的修改有一部分已写入物理数据库，这时数据库就处于一种不正确的状态，或者说是 不一致的状态。

3 、隔离性。一个事务的执行不能其它事务干扰。即一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰。

4 、持续性。也称永久性，指一个事务一旦提交，它对数据库中的数据的改变就应该是永久性的。接下来的其它操作或故障不应该对其执行结果有任何影响。



## 3.分库分表的原理与实现方式

#### 3.1 水平分库

![数据库-水平分库](picture\数据库-水平分库.png)

**概念：**

以**字段**为依据，按照一定策略（hash、range等），将一个**库**中的数据拆分到多个**库**中。

**结果：**

- 每个**库**的**结构**都一样；
- 每个**库**的**数据**都不一样，没有交集；
- 所有**库**的**并集**是全量数据；

**场景：**

系统绝对并发量上来了，分表难以根本上解决问题，并且还没有明显的业务归属来垂直分库。

**分析：**

库多了，io和cpu的压力自然可以成倍缓解。



#### 3.2 水平分表

![数据库-水平分表](picture\数据库-水平分表.png)

**概念：**

以**字段**为依据，按照一定策略（hash、range等），将一个**表**中的数据拆分到多个**表**中。

**结果：**

- 每个**表**的**结构**都一样；
- 每个**表**的**数据**都不一样，没有交集；
- 所有**表**的**并集**是全量数据；

**场景：**

系统绝对并发量并没有上来，只是单表的数据量太多，影响了SQL效率，加重了CPU负担，以至于成为瓶颈。

**分析：**

表的数据量少了，单次SQL执行效率高，自然减轻了CPU的负担。



#### 3.3 垂直分库

![数据库-垂直分库](picture\数据库-垂直分库.png)

**概念：**

以**表**为依据，按照业务归属不同，将不同的**表**拆分到不同的**库**中。

**结果：**

- 每个**库**的**结构**都不一样；
- 每个**库**的**数据**也不一样，没有交集；
- 所有**库**的**并集**是全量数据；

**场景：**

系统绝对并发量上来了，并且可以抽象出单独的业务模块。

**分析：**

到这一步，基本上就可以服务化了。例如，随着业务的发展一些公用的配置表、字典表等越来越多，这时可以将这些表拆到单独的库中，甚至可以服务化。再有，随着业务的发展孵化出了一套业务模式，这时可以将相关的表拆到单独的库中，甚至可以服务化。



#### 3.4 垂直分表

![数据库-垂直分表](picture\数据库-垂直分表.png)

**概念：**

以**字段**为依据，按照字段的活跃性，将**表**中字段拆到不同的**表**（主表和扩展表）中。

**结果：**

- 每个**表**的**结构**都不一样；
- 每个**表**的**数据**也不一样，一般来说，每个表的**字段**至少有一列交集，一般是主键，用于关联数据；
- 所有**表**的**并集**是全量数据；

**场景：**

系统绝对并发量并没有上来，表的记录并不多，但是字段多，并且热点数据和非热点数据在一起，单行数据所需的存储空间较大。以至于数据库缓存的数据行减少，查询时会去读磁盘数据产生大量的随机读IO，产生IO瓶颈。

**分析：**

可以用列表页和详情页来帮助理解。垂直分表的拆分原则是将热点数据（可能会冗余经常一起查询的数据）放在一起作为主表，非热点数据放在一起作为扩展表。这样更多的热点数据就能被缓存下来，进而减少了随机读IO。拆了之后，要想获得全部数据就需要关联两个表来取数据。但记住，千万别用join，因为join不仅会增加CPU负担并且会讲两个表耦合在一起（必须在一个数据库实例上）。关联数据，应该在业务Service层做文章，分别获取主表和扩展表数据然后用关联字段关联得到全部数据。



## 4.mysql

#### 4.1**MySQL目前主要有以下几种索引类型：**

**1.普通索引**

**2.唯一索引**

**3.主键索引**

**4.组合索引**

**5.全文索引**

#### 4.2 **回表:(可以使用索引覆盖避免回表)**

**每创建一个索引就会创建个B+树，如果通过id住建和name创建了索引，在执行下面的sql时。**

**1.首先去name的B+树找到对应的值，值是id，2.再通过id的B+树找到对应的值取出**

**为什么回表**：MySQL innodb的主键索引是簇集索引，也就是索引的叶子节点存的是整个单条记录的所有字段值，不是主键索引的就是非簇集索引，非簇集索引的叶子节点存的是主键字段的值

![mysql-回表](picture\mysql-回表.png)

#### 4.3 **索引覆盖：**

  **还是上面回表的两张表：**

  **第一个sql:** **select id,name from t where name='lisi'**

**能够命中name索引，索引叶子节点存储了主键id，通过name的索引树即可获取id和name，无需回表，符合索引覆盖，效率较高**

 **第一个sql:** **select id,name,sex from t where name='lisi'**

​       **能够命中name索引，索引叶子节点存储了主键id，但sex字段必须回表查询才能获取到，不符合索引覆盖，需要再次通过id值扫码聚集索引获取sex字段，效率会降低**

​       **如果把(name)单列索引升级为联合索引(name, sex)就不同了。可以看到，能够命中索引覆盖，无需回表**



#### 4.4 最左匹配原则

​	**最左匹配原则就是指在联合索引中，如果你的 SQL 语句中用到了联合索引中的最左边的索引，那么这条 SQL 语句就可以利用这个联合索引去进行匹配。例如某表现有索引(a,b,c)，现在你有如下语句：**

select * from t where a=1 and b=1 and c =1; 			 #这样可以利用到定义的索引（a,b,c） 

select * from t where a=1 and b=1;					 #这样可以利用到定义的索引（a,b,c） 

select * from t where a=1;						 #这样也可以利用到定义的索引（a,b,c） 

select * from t where b=1 and c=1; 					 #这样不可以利用到定义的索引（a,b,c） 

select * from t where a=1 and c=1; 					 #这样不可以利用到定义的索引（a,b,c）

**也就是说通过最左匹配原则你可以定义一个联合索引，但是使得多中查询条件都可以用到该索引。值得注意的是，当遇到范围查询(>、<、between、like)就会停止匹配。也就是：**

**select** ***** **from** t **where** a**=**1 **and** b**>**1 **and** **c** **=**1;     **#**这样a,b可以用到（a,b,**c**），c不可以

**总结：**

在 InnoDB 中联合索引只有先确定了前一个（左侧的值）后，才能确定下一个值。如果有范围查询的话，那么联合索引中使用范围查询的字段后的索引在该条 SQL 中都不会起作用。

值得注意的是，in 和 = 都可以乱序，比如有索引（a,b,c），语句 select * from t where c =1 and a=1 and b=1，这样的语句也可以用到最左匹配，因为 MySQL 中有一个优化器，他会分析 SQL 语句，将其优化成索引可以匹配的形式，即 select * from t where a =1 and a=1 and c=1



#### 4.5 sql的left join 、right join 、inner join之间的区别

　　left join(左联接) 返回包括左表中的所有记录和右表中联结字段相等的记录 
　　right join(右联接) 返回包括右表中的所有记录和左表中联结字段相等的记录
　　inner join(等值连接) 只返回两个表中联结字段相等的行



#### **4.6 锁**   

#####  4.5.1 表锁

 **读锁(共享锁)：针对同一份数据，多个读操作可以同时进行互不影响          lock table 表名 read;**

  **例子：session1给book表加了读锁，它可以读取book表，但是不能读取其它的表，而且不能修改book表里的数据**

​             **session2可以读取book表，也可以读取和修改其它未加锁的表，但是它修改book表时会阻塞，直至book表释放了锁**

  **写锁(排它锁) ：当前操作没有完成之前，它会阻断其他写锁和读锁          lock table 表名 write;**

 **例子：   session1给book表加了写锁，它可以读取book表，能修改和读book表，但是不能读取和修改其它锁。**

​             **session2修改和读book表时会阻塞，直至book表释放了锁**

**总结：简而言之，就是读锁会阻塞写，但是不会阻塞读。而写锁则会把读和写全部阻塞**

##### 4.5.2 行锁

   **行锁的劣势：开销大；加锁慢；会出现死锁**

   **行锁的优势：锁的粒度小，发生锁冲突的概率低；处理并发的能力强**

   **加锁的方式：自动加锁。对于UPDATE、DELETE和INSERT语句，InnoDB会自动给涉及数据集加排他锁；对于普通SELECT语句，InnoDB不会加任何锁；当然我们也可以显示的加锁：**

   **共享锁：select \* from tableName where ... + lock in share more**

   **排他锁：select \* from tableName where ... + for update**



# RabbitMQ

> 1. rabbitmqctl stop_app - 关闭应用
>
> 2. rabbitmqctl reset - 清除队列中的消息
>
> 3. rabbitmqctl start_app - 再次启动此应用

## 1.RabbitMQ六种工作方式

### 1.1 简单模式

> 一个生产者，一个消费者

![mq-简单模式](picture\mq-简单模式.jpg)



### 1.2 Work queues(工作模式)

> work queues与入门程序相比，多了一个消费端，两个消费端共同消费同一个队列中的消息。

应用场景：对于 任务过重或任务较多情况使用工作队列可以提高任务处理的速度。

测试：

1、使用入门程序，启动多个消费者。

2、生产者发送多个消息。

结果：

1、一条消息只会被一个消费者接收；

2、rabbit采用轮询的方式将消息是平均发送给消费者的；

3、消费者在处理完某条消息后，才会收到下一条消息。

![mq-工作模式](picture\mq-工作模式.jpg)



### 1.3 Publish/subscribe(发布订阅模式)

> 1、每个消费者监听自己的队列。
>
> 2、生产者将消息发给broker，由交换机将消息转发到绑定此交换机的每个队列，每个绑定交换机的队列都将接收到消息

1.定义一个订阅模式的交换机：FanoutExchange交换机。
2.创建2个队列helloA，helloB，然后将这两个队列绑定到交换机上面。

![mq-发布订阅](picture\mq-发布订阅模式.jpg)



### 1.4 Routing(路由模式)

> 1、每个消费者监听自己的队列，并且设置routingkey。
>
> 2、生产者将消息发给交换机，由交换机根据routingkey来转发消息到指定的队列。

![mq-路由模式](picture\mq-路由模式.jpg)



### 1.5 Topics(通配符模式)

> 1、每个消费者监听自己的队列，并且设置带统配符的routingkey。
>
> 2、生产者将消息发给broker，由交换机根据routingkey来转发消息到指定的队列。

![mq-topic模式](picture\mq-topic模式.jpg)



## 2.如何保证高可用性和幂等性

### 2.1 解决幂等性

**全局唯一ID + Redis**



### 2.2 保证消息不丢失

#### 2.2.1生产者

1.通过实现 ConfirmCallback 接口，消息发送到 Broker 后触发回调，确认消息是否到达 Broker 服务器,也就是只确认是否正确到达 Exchange 中

2.通过实现 ReturnCallback 接口，启动消息失败返回，比如路由不到队列时触发回调



#### 2.2.2 消费者

1.通过手动ack和手动签收保证消息被正确消费了

2.开启消费者(程序出现异常)重试机制，默认开启并一直重试



#### 2.2.3 死信队列

由于某些原因消息无法被正确的投递，为了确保消息不会被无故的丢弃，一般将其置于一个特殊角色的队列，这个队列一般称之为死信队列



#### 2.2.4 延迟队列

给绑定的队列A设置设置队列中的所有消息的生存周期(Message TTL(x-message-ttl)），同时绑定死信队列，此时队列A不进行消费，这时生存周期一过，就会进入到死信队列，这时死信队列进行消费，这时就实现了延迟队列的作用



# Redis

## 1.Redis五种数据类型

### 1.1 String

> string 是 redis 最基本的类型，你可以理解成与 Memcached 一模一样的类型，一个 key 对应一个 value。
>
> 常用命令：set、get、decr、incr、mget等。



### 1.2 **Hash（哈希）**

> Redis hash 是一个键值(key=>value)对集合；是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象。
>
> 常用命令：hget、hset、hgetall等。

应用场景：存储一些结构化的数据，比如用户的昵称、年龄、性别、积分等，存储一个用户信息对象数据。



### 1.3 **List（列表）**

> Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。
>
> 常用命令：lpush、rpush、lpop、rpop、lrange等。

list类型经常会被用于消息队列的服务，以完成多程序之间的消息交换。



### 1.4 **Set（集合）**

> Redis的Set是string类型的无序集合。和列表一样，在执行插入和删除和判断是否存在某元素时，效率是很高的
>
> 常用命令：sadd、spop、smembers、sunion等。

应用场景：

1、利用交集求共同好友。

2、利用唯一性，可以统计访问网站的所有独立IP。

3、好友推荐的时候根据tag求交集，大于某个threshold（临界值的）就可以推荐。



### 1.5 **zset(sorted set：有序集合)**

> Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。zset的成员是唯一的,但分数(score)却可以重复。
>
> 常用命令：zadd、zrange、zrem、zcard等。

当你需要一个有序的并且不重复的集合列表时，那么可以选择sorted set数据结构。

应用举例：

（1）例如存储全班同学的成绩，其集合value可以是同学的学号，而score就可以是成绩。
（2）排行榜应用，根据得分列出topN的用户等。



## 2 Redis的失效策略

> **参考文献：**https://www.cnblogs.com/dudu2mama/p/11366292.html

- noeviction: 不删除策略, 达到最大内存限制时, 如果需要更多内存, 直接返回错误信息。 大多数写命令都会导致占用更多的内存(有极少数会例外, 如 [DEL](https://redis.io/commands/del) )。
- allkeys-lru：所有key通用; 优先删除最近最少使用(less recently used ,LRU) 的 key。
- allkeys-random： 所有key通用; 随机删除一部分 key。
- volatile-lru：只限于设置了 expire 的部分; 优先删除最近最少使用(less recently used ,LRU) 的 key。
- volatile-random：只限于设置了 expire 的部分; 随机删除一部分 key。
- volatile-ttl：只限于设置了 expire 的部分; 优先删除剩余时间(time to live,TTL) 短的key。



## 3.Redis的持久化方式

#### 3.1 AOF(快照)持久化配置

Redis会将数据集的快照dump到dump.rdb文件中。此外，我们也可以通过配置文件来修改Redis服务器dump快照的频率，在打开6379.conf文件之后，我们搜索save，可以看到下面的配置信息：

save 900 1       #在900秒(15分钟)之后，如果至少有1个key发生变化，则dump内存快照。

save 300 10      #在300秒(5分钟)之后，如果至少有10个key发生变化，则dump内存快照。

save 60 10000    #在60秒(1分钟)之后，如果至少有10000个key发生变化，则dump内存快照。

#### 3.2 RDB持久化配置

ppendfsync always   #每次有数据修改发生时都会写入AOF文件。

appendfsync everysec #每秒钟同步一次，该策略为AOF的缺省策略。

appendfsync no     #从不同步。高效但是数据不会被持久化。

## 4.Redis的三种集群方式

> **参考文献：**https://www.cnblogs.com/51life/p/10233340.html

redis有三种集群方式：主从复制，哨兵模式和集群。

### 4.1 主从复制

> 1.主机会自动将数据同步到从机，可以进行读写分离
>
> 2.Redis不具备自动容错和恢复功能，如果主机宕机不能自动切换



### 4.2 哨兵模式

> 1.监控主服务器和从服务器是否正常运行。 
>
> 2.主服务器出现故障时自动将从服务器转换为主服务器。



### 4.3 Redis-Cluster 集群

redis的哨兵模式基本已经可以实现高可用，读写分离 ，但是在这种模式下每台redis服务器都存储相同的数据，很浪费内存，所以在redis3.0上加入了cluster模式，实现的redis的分布式存储，也就是说每台redis节点上存储不同的内容。

在redis的每一个节点上，都有这么两个东西，一个是插槽（slot），它的的取值范围是：0-16383。还有一个就是cluster，可以理解为是一个集群管理的插件。当我们的存取的key到达的时候，redis会根据crc16的算法得出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，通过这个值，去找到对应的插槽所对应的节点，然后直接自动跳转到这个对应的节点上进行存取操作。

为了保证高可用，redis-cluster集群引入了主从模式，一个主节点对应一个或者多个从节点，当主节点宕机的时候，就会启用从节点。当其它主节点ping一个主节点A时，如果半数以上的主节点与A通信超时，那么认为主节点A宕机了。如果主节点A和它的从节点A1都宕机了，那么该集群就无法再提供服务了。



## 5.缓存雪崩 缓存穿透 缓存击穿

>   **参考文献:**  https://www.cnblogs.com/xichji/p/11286443.html



## 6 Redis分布式锁

```java
/**
 * redis工具类
 *
 */
@Component
public class RedisUtil {
   
   private static Logger logger = LoggerFactory.getLogger(RedisUtil.class);
   
   @Autowired
   private RedisTemplate<Object, Object> redisTemplate;
   
   @Autowired
   private StringRedisTemplate stringRedisTemplate;
   
   /**
    * 设置过期时间
    * @param key
    * @param time, 默认时间单位，秒
    * @return
    */
   public boolean expire(String key, long time) {
        return this.expire(key, time, null);
    }
   
   /**
    * 设置过期时间
    * @param key
    * @param time
    * @param unit
    * @return
    */
   public boolean expire(String key, long time, TimeUnit unit) {
        try {
            if (time > 0) {
               redisTemplate.expire(key, time, unit == null ? TimeUnit.SECONDS : unit);
            }
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }
   
    /**
     * 获取过期时间
     * @param key
     * @return
     */
    public long getExpire(String key) {
        return redisTemplate.getExpire(key, TimeUnit.SECONDS);
    }
    
    /**
     * 查询key是否存在
     * @param key
     * @return
     */
    public boolean hasKey(String key) {
        try {
            return redisTemplate.hasKey(key);
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }
    
    /**
     * 删除缓存
     * @param key 可以传一个值 或多个
     */
    @SuppressWarnings("unchecked")
   public void del(String... key) {
        if (key != null && key.length > 0) {
            if (key.length == 1) {
               redisTemplate.delete(key[0]);
            } else {
               redisTemplate.delete(CollectionUtils.arrayToList(key));
            }
        }
    }
   
   /**
    * 查询对象值
    * @param key
    * @return
    */
   public Object getObject(String key) {
      return redisTemplate.opsForValue().get(key);
   }
   
   /**
    * 查询字符串值
    * @param key
    * @return
    */
   public String getString (String key) {
      return (String)getObject(key);
   }
   
    /**
     * 普通缓存放入,默认无过期时间
     * @param key 键
     * @param value 值
     * @return true成功 false失败
     */
    public boolean set(String key, Object value) {
       return set(key, value, 0, null);
    }
   
    /**
     * 普通缓存放入
     * @param key
     * @param value
     * @param timeout
     * @param unit
     * @return true成功 false失败
     */
    public boolean set(String key, Object value, long timeout, TimeUnit unit) {
        try {
           if(timeout > 0) {
              redisTemplate.opsForValue().set(key, value, timeout, unit);
           }else {
              redisTemplate.opsForValue().set(key, value);
           }
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }
    
    public boolean lock(String key, String uniqueIdentifier, long timeout) {
        if (stringRedisTemplate.opsForValue().setIfAbsent(key, uniqueIdentifier)) {
           stringRedisTemplate.expire(key, timeout, TimeUnit.MILLISECONDS);
           return true;
        }
        //判断锁超时 - 防止原来的操作异常，没有运行解锁操作  防止死锁
        String uuidWithTime = stringRedisTemplate.opsForValue().get(key);
        //如果锁过期
        if (StringUtils.isNotEmpty(uuidWithTime)) {
            long timeMillis = Long.parseLong(uuidWithTime.split("\\|")[1]);
            if (timeMillis < System.currentTimeMillis()) {
                // 得到原来锁的旧值并且设置新值
                String oldValue = stringRedisTemplate.opsForValue().getAndSet(key, uniqueIdentifier);
                stringRedisTemplate.expire(key, timeout, TimeUnit.MILLISECONDS);
                // oldValue不能为空(保证此时key还存在)，oldValue.equals(uuidWithTime)保证还是初始的key,并没有进行新的加锁赋值
                return StringUtils.isNotEmpty(oldValue) && oldValue.equals(uuidWithTime);
            }
        }
        return false;
    }

    public void unlock(String key, String uniqueIdentifier) {
       try {
            String identifier = stringRedisTemplate.opsForValue().get(key);
            if (StringUtils.isNotEmpty(identifier) && identifier.equals(uniqueIdentifier))
                stringRedisTemplate.delete(key);
        } catch (Exception e) {
            logger.error("[Redis锁] 解锁出现异常了，{}", e);
        }
    }
}
```

### 7.1 Redis和Redission

#### Redis分布式锁的不足：

> 1.通过setnx设置锁后再设置过期时间，此时如果宕机了，锁没有过期时间就会造成死锁(通过setIfAbsent(lockKey, uuid,10*1000, TimeUnit.SECONDS)解决)
>
> 2.任务超时，导致其它线程删除了不是当前线程的key(可以使用唯一标识uuid+时间戳去进行比较)
>
> 3.锁的失效期不容易控制，如果过小任务可能执行不完锁就被其它线程拿到了，过大宕机了可能导致死锁(此时可以使用守护线程进行循环添加过期时间，保证任务能在拿到锁的期间执行完成)

```java
String lockKey = "lockKey";
String uuid = UUID.randomUUID().toString();
try {
    // 设置setnx并且设置过期时间
    Boolean flag = stringRedisTemplate.opsForValue().setIfAbsent(lockKey, uuid,10*1000, TimeUnit.SECONDS);
    if(flag){
        Integer stock =  Integer.parseInt(stringRedisTemplate.opsForValue().get("stock"));
        if(stock>0){
            int resultStock = stock - 1;
            stringRedisTemplate.opsForValue().set("stock",resultStock+"");
            System.out.println("剩余库存："+resultStock);
        }else{
            System.out.println("剩余库存不足：");
        }

    }else{
        System.out.println("未获取到锁");
    }

}finally {
    // 防止任务超时，其它线程删除当前线程的key
    if(uuid.equals(stringRedisTemplate.opsForValue().get(lockKey))){
        stringRedisTemplate.delete(lockKey);
    }
}
```

#### Redisson

Reddission的工作原理：

   运用lua脚本进行设置锁，和reddis异曲同工

<img src="picture\reddisson.png" alt="reddisson" style="zoom:67%;" />



引入依赖之后还要加入

```java
@Bean
public RedissonClient getRedisson(){
    Config config = new Config();
    //单机模式  依次设置redis地址和密码
    config.useSingleServer().
            setAddress("redis://127.0.0.1:6379").
            setPassword("123456");
    return Redisson.create(config);
}
```



```java
@GetMapping("/deductStockRedission")
public String deductStockRedission(){
    String lockKey = "lockKey";
    RLock redissonLock = redissonClient.getLock(lockKey);

    try {
        //redissonLock.lock();  // 如果线程没有获取到锁则会排队等待
        /**
         * 尝试获取锁
         * waitTimeout 尝试获取锁的最大等待时间，超过这个值，则认为获取锁失败
         * leaseTime   锁的持有时间,超过这个时间锁会自动失效（值应设置为大于业务处理的时间，确保在锁有效期内业务能处理完）
         */
        if(redissonLock.tryLock()){
            Integer stock =  Integer.parseInt(stringRedisTemplate.opsForValue().get("stock"));
            if(stock>0){
                int resultStock = stock - 1;
                stringRedisTemplate.opsForValue().set("stock",resultStock+"");
                System.out.println("剩余库存："+resultStock);
            }else{
                System.out.println("剩余库存不足：");
            }
        }else{
            System.out.println("获取不到锁");
        }

    }finally {
        if(redissonLock.isLocked()){ // 是否还是锁定状态
            if(redissonLock.isHeldByCurrentThread()){ // 时候是当前执行线程的锁
                redissonLock.unlock(); // 释放锁
            }
        }
    }

    return "end";
}
```



## 7 Redis 和Zookpeer的区别

<img src="picture\reddisson.png" alt="reddisson" style="zoom:60%;" />

Redis的主从复制，哨兵，集群等都是CP原则(高可用和分区容错性)

> 会有一个问题，虽然效率非常高，因为线程1加锁成功，Redis的主节点直接返回了结果之后才会给Redis的从节点添加key值，此时如果主节点突然挂掉还没有来得及给Redis的从节点添加key值，Redis选举Redis的从节点成为了主节点，这时线程1还在进行加锁操作，线程2同时也获取到了锁，此时就会出现锁失效问题

Zookpeer是AP原则(一致性和分区容错性)

> Zookpeer是主节点添加完key值后不立即返回结果，而是从节点也成功添加了key值才会返回结果，虽然解决了Redis的锁失效问题，但是效率明显不如Redis

























# 重点进阶知识

## 1.ThreadLocal

> **参考文献：**https://baijiahao.baidu.com/s?id=1653790035315010634&wfr=spider&for=pc

**代码：**

   **工具类：taimeiKnowledge\src\main\java\com\zys\taimeiknowledge\util\SystemContext.java**

   **测试用例：taimeiKnowledge\src\main\java\com\zys\taimeiknowledge\Test\ThreadLocal\ThreadLocalTest.java**

**ThreadLocal解决跨线程问题：**

```java
    ExecutorService executorService =
                Executors.newFixedThreadPool(5);
        
        SystemContext.put("tm","111");
        Map<String, String> contextMap = SystemContext.getContextMap();
        executorService.execute(new Runnable() {
            @SneakyThrows
            @Override
            public void run() {
                System.out.println(Thread.currentThread().getName()+"---->"+SystemContext.get("tm"));
            }
        });

        // 跨线程赋值ThreadLocal(其实就是把ThreadLocal再次赋值到新的线程里)
        executorService.execute(new Runnable() {
            @Override
            public void run() {
                // 开启了新的线程，main函数的ThreadLocal值拿不到，只能再次赋值
                SystemContext.setContextMap(contextMap);
                System.out.println(Thread.currentThread().getName()+"---->"+SystemContext.get("tm"));
            }
        });


        // main函数的ThreadLocal
        System.out.println(Thread.currentThread().getName()+"---->"+SystemContext.get("tm"));
```



## 2.线程池

> **参考文献：**https://blog.csdn.net/mu_wind/article/details/113806680

**代码：**

  **测试用例：taimeiKnowledge\src\main\java\com\zys\taimeiknowledge\Test\ThreadPool**



## 3.TransmittableThreadLocal

  **阿里用来解决ThreadLocal跨线程问题的中间件**



## 4.强引用，软引用，弱引用和虚引用

> **参考文献：**https://blog.csdn.net/junjunba2689/article/details/80601729

**1．强引用**：

    **以前我们使用的大部分引用实际上都是强引用，这是使用最普遍的引用**。如果一个对象具有强引用，那就类似于必不可少的生活用品，垃圾回收器绝不会回收它。**当内存空间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题**。

**2、软引用（SoftReference）**:

   如果一个对象只具有软引用，那就类似于可有可物的生活用品。**如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。**只要垃圾回收器没有回收它，该对象就可以被程序使用。**软引用可用来实现内存敏感的高速缓存。**

**3．弱引用（WeakReference）**:

​    如果一个对象只具有弱引用，那就类似于可有可物的生活用品。**弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它 所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。**不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。

**4．虚引用（PhantomReference）**:

​    “虚引用”顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就**和没有任何引用一样，在任何时候都可能被垃圾回收。虚引用主要用来跟踪对象被垃圾回收的活动**。虚引用与软引用和弱引用的一个区别在于：**虚引用必须和引用队列（ReferenceQueue）联合使用**。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。程序如果发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。



## 5.Redis

### 5.1 缓存雪崩 缓存穿透 缓存击穿

>   **参考文献:**  https://www.cnblogs.com/xichji/p/11286443.html

### 5.2Redis的三种集群方式

> **参考文献：**https://www.cnblogs.com/51life/p/10233340.html

主从复制；哨兵；**Redis-Cluster**集群

### 5.3 Redis分布式锁

### 5.4 Redis的失效策略

> **参考文献：**https://www.cnblogs.com/dudu2mama/p/11366292.html



### 6.数据库的悲观和乐观锁

> 参考文献：https://www.cnblogs.com/kyoner/p/11318979.html